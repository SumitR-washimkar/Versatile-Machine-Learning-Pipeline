{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b59d3354-23ba-4cfe-8600-b8027b126d01",
   "metadata": {},
   "source": [
    "<font size='5'>**Introduction**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadcc6a-8588-4832-a861-328d85944585",
   "metadata": {},
   "source": [
    "**Title: Versatile Machine Learning Pipeline**\n",
    "\n",
    "Description:\n",
    "This script implements a comprehensive machine learning pipeline designed to handle both classification and regression tasks. It processes a dataset specified in a configuration file (\"algoparams_from_ui.json\"), performs feature engineering, trains a model, and evaluates its performance. The pipeline includes the following key stages:\n",
    "\n",
    "1. **Data Loading and Preprocessing**:\n",
    "   - Loads the dataset from a CSV file specified in the configuration.\n",
    "   - Handles numerical and categorical features, converts categorical feature to numerical by encoding, using `FeatureHasher`.\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Generates new features through linear, polynomial, and explicit pairwise interactions as defined in the configuration.\n",
    "   - Applies `RobustScaler` to scale the generated features for better model performance.\n",
    "\n",
    "3. **Feature Reduction**:\n",
    "   - Supports multiple feature reduction techniques (e.g., Correlation with Target, Tree-based, PCA) to reduce dimensionality while retaining the most important features.\n",
    "   - The method and number of features to keep are specified in the configuration.\n",
    "\n",
    "4. **Model Training**:\n",
    "   - Supports a variety of algorithms (e.g., RandomForest, Gradient Boosting, Linear Models, SVM, XGBoost, etc.) for both regression and classification tasks.\n",
    "   - Uses hyperparameter tuning with Grid Search if specified, and applies sample weighting for classification tasks if configured.\n",
    "   - Trains the model on a split dataset (80% train, 20% test) using `train_test_split`.\n",
    "\n",
    "5. **Evaluation**:\n",
    "   - For classification tasks, evaluates the model using F1 Score, Accuracy, Recall, and Precision.\n",
    "   - For regression tasks, computes Mean Squared Error (MSE) and RÂ² Score.\n",
    "   - Ensures robust evaluation by handling prediction types appropriately and providing clear metrics output.\n",
    "\n",
    "The pipeline is highly configurable through the \"algoparams_from_ui.json\" file, allowing users to customize feature handling, model selection, hyperparameter tuning, and evaluation metrics. This script is designed to be flexible and reusable for various datasets and machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e903127-86a9-46f3-87bc-dfcc04212adc",
   "metadata": {},
   "source": [
    "<font size='5'>**Importing Dataset and Loading JSON File**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9abd4-f7f9-462b-9fc3-adb416a51e65",
   "metadata": {},
   "source": [
    "### Loading JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29eeb63-38ac-4f90-9c4c-c640f4a4c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ff4940-bcc0-45fc-8f06-3eeb4e53ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"algoparams_from_ui.json\") as f:\n",
    "    config=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cda183-63bd-4b7c-98b2-f142383445c9",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2600dc1e-123d-4cc2-9fa0-f8c7888463be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "original_data = pd.read_csv(config['design_state_data']['session_info']['dataset'])\n",
    "df=original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1933e1f7-65f3-473e-96d5-f0fe6e859adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5           5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6           4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7           5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8           4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9           4.9          3.1           1.5          0.1  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d3ec07-df8b-4868-9548-1f5ff6dcd608",
   "metadata": {},
   "source": [
    "<font size='5'>**Preprocesing**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104a62f-d5a3-41b6-9d58-9c81d7207475",
   "metadata": {},
   "source": [
    "### Feature Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047ab86e-8921-46d0-b80a-cc9a3d2de57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "df = pd.DataFrame(df)\n",
    "for col in config['design_state_data']['feature_handling']:\n",
    "    if config['design_state_data']['feature_handling'][col]['feature_variable_type']=='numerical':\n",
    "        continue\n",
    "    else:\n",
    "        data_values = df[col].tolist()\n",
    "        data_list = [[values] for values in data_values]\n",
    "        n_features = df[col].value_counts().count()-1\n",
    "        hasher = FeatureHasher(n_features=n_features, input_type='string')\n",
    "        hashed_features = hasher.fit_transform(data_list)\n",
    "        hashed_features_dense = hashed_features.toarray()\n",
    "        hashed_df = pd.DataFrame(hashed_features_dense, columns=[f'species_hashed_{i}' for i in range(n_features)])\n",
    "        df = df.drop(col, axis=1)\n",
    "        df = pd.concat([df, hashed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff08a97-0d67-4ed6-98ef-77b21162c4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species_hashed_0</th>\n",
       "      <th>species_hashed_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species_hashed_0  \\\n",
       "99            5.7          2.8           4.1          1.3              -1.0   \n",
       "18            5.7          3.8           1.7          0.3               0.0   \n",
       "137           6.4          3.1           5.5          1.8               0.0   \n",
       "94            5.6          2.7           4.2          1.3              -1.0   \n",
       "40            5.0          3.5           1.3          0.3               0.0   \n",
       "4             5.0          3.6           1.4          0.2               0.0   \n",
       "118           7.7          2.6           6.9          2.3               0.0   \n",
       "39            5.1          3.4           1.5          0.2               0.0   \n",
       "134           6.1          2.6           5.6          1.4               0.0   \n",
       "41            4.5          2.3           1.3          0.3               0.0   \n",
       "\n",
       "     species_hashed_1  \n",
       "99                0.0  \n",
       "18                1.0  \n",
       "137              -1.0  \n",
       "94                0.0  \n",
       "40                1.0  \n",
       "4                 1.0  \n",
       "118              -1.0  \n",
       "39                1.0  \n",
       "134              -1.0  \n",
       "41                1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f46b0-56da-42e2-96cd-917c0505043e",
   "metadata": {},
   "source": [
    "<font size='5'>**Feature Engineering**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8739ee-82cf-41fd-9867-8cf5f764f3fa",
   "metadata": {},
   "source": [
    "### Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2d2eb-7a39-4b25-a4cd-193b0f6157fa",
   "metadata": {},
   "source": [
    "1) The column 'species_sum' is created so that any encoded column can be used to generate a new feature, not just a single encoded column.\n",
    "2) A warning is generated if an unknown feature generation technique is used that is not defined in the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0d335a-b05b-4059-9d5a-a835dd33dacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumit Washimkar SRW\\AppData\\Local\\Temp\\ipykernel_15468\\1638888852.py:45: UserWarning: Unknown feature generation method: linear_scalar_type\n",
      "  warnings.warn(f\"Unknown feature generation method: {interaction}\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "for interaction in config['design_state_data']['feature_generation']:\n",
    "    if interaction == 'linear_interactions':\n",
    "        for columns in config['design_state_data']['feature_generation'][interaction]:\n",
    "            feat1, feat2 = columns\n",
    "            if feat2 not in df.columns:\n",
    "                matching_cols = [col for col in df.columns if col.startswith(feat2 + '_')]\n",
    "                if len(matching_cols) > 1:\n",
    "                    df[f'{feat2}_sum'] = df[matching_cols].sum(axis=1)\n",
    "                    feat2 = f'{feat2}_sum'\n",
    "                else:\n",
    "                    feat2 = feat2\n",
    "            df[interaction] = df[feat1] + df[feat2]\n",
    "            scaler = RobustScaler()\n",
    "            df[[interaction]] = scaler.fit_transform(df[[interaction]])\n",
    "\n",
    "    elif interaction == 'polynomial_interactions':\n",
    "        for columns in config['design_state_data']['feature_generation'][interaction]:\n",
    "            feat1, feat2 = columns.split('/')\n",
    "            if feat2 not in df.columns:\n",
    "                matching_cols = [col for col in df.columns if col.startswith(feat2 + '_')]\n",
    "                if len(matching_cols) > 1:\n",
    "                    df[f'{feat2}_sum'] = df[matching_cols].sum(axis=1)\n",
    "                    feat2 = f'{feat2}_sum'\n",
    "                else:\n",
    "                    feat2 = feat2\n",
    "            epsilon = 1e-6\n",
    "            df[f'{feat1}_div_{feat2}'] = df[feat1] / (df[feat2] + epsilon)\n",
    "\n",
    "    elif interaction == 'explicit_pairwise_interactions':\n",
    "        for columns in config['design_state_data']['feature_generation'][interaction]:\n",
    "            feat1, feat2 = columns.split('/')\n",
    "            if feat2 not in df.columns:\n",
    "                matching_cols = [col for col in df.columns if col.startswith(feat2 + '_')]\n",
    "                if len(matching_cols) > 1:\n",
    "                    df[f'{feat2}_sum'] = df[matching_cols].sum(axis=1)\n",
    "                    feat2 = f'{feat2}_sum'\n",
    "                else:\n",
    "                    feat2 = feat2\n",
    "            epsilon = 1e-6\n",
    "            df[f'{feat1}_div_{feat2}'] = df[feat1] / (df[feat2] + epsilon)\n",
    "\n",
    "    else:\n",
    "        warnings.warn(f\"Unknown feature generation method: {interaction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf150d7f-2d93-408e-9ee4-14c4724905ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species_hashed_0</th>\n",
       "      <th>species_hashed_1</th>\n",
       "      <th>linear_interactions</th>\n",
       "      <th>petal_length_div_sepal_width</th>\n",
       "      <th>species_sum</th>\n",
       "      <th>petal_width_div_species_sum</th>\n",
       "      <th>sepal_width_div_sepal_length</th>\n",
       "      <th>petal_width_div_sepal_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.100002</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.308823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.767857</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.839286</td>\n",
       "      <td>0.371428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>1.999999</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.200002</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>1.666666</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.700002</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.253731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species_hashed_0  \\\n",
       "112           6.8          3.0           5.5          2.1               0.0   \n",
       "4             5.0          3.6           1.4          0.2               0.0   \n",
       "40            5.0          3.5           1.3          0.3               0.0   \n",
       "132           6.4          2.8           5.6          2.2               0.0   \n",
       "77            6.7          3.0           5.0          1.7              -1.0   \n",
       "\n",
       "     species_hashed_1  linear_interactions  petal_length_div_sepal_width  \\\n",
       "112              -1.0             0.482143                      1.833333   \n",
       "4                 1.0            -0.767857                      0.388889   \n",
       "40                1.0            -0.839286                      0.371428   \n",
       "132              -1.0             0.446429                      1.999999   \n",
       "77                0.0             0.303571                      1.666666   \n",
       "\n",
       "     species_sum  petal_width_div_species_sum  sepal_width_div_sepal_length  \\\n",
       "112         -1.0                    -2.100002                      0.441176   \n",
       "4            1.0                     0.200000                      0.720000   \n",
       "40           1.0                     0.300000                      0.700000   \n",
       "132         -1.0                    -2.200002                      0.437500   \n",
       "77          -1.0                    -1.700002                      0.447761   \n",
       "\n",
       "     petal_width_div_sepal_length  \n",
       "112                      0.308823  \n",
       "4                        0.040000  \n",
       "40                       0.060000  \n",
       "132                      0.343750  \n",
       "77                       0.253731  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049af53-1c28-4f3c-b64e-faa2b6e27679",
   "metadata": {},
   "source": [
    "### Feature Reduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f85a43-76f6-4b09-973e-7334af759947",
   "metadata": {},
   "source": [
    "1) The 'species_sum' column is removed from X, as it is only an intermediate column used during feature generation.\n",
    "2) A warning is generated if an unknown feature reduction technique is used that is not defined in the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83672da-a858-44d8-9bea-46c771d684bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "target_column=config['design_state_data']['target']['target']\n",
    "X = df.drop(columns=[target_column])\n",
    "\n",
    "X = X.drop(columns=['species_sum'], errors='ignore')\n",
    "\n",
    "y = df[target_column]\n",
    "\n",
    "feature_reduction_cfg = config['design_state_data']['feature_reduction']\n",
    "method = feature_reduction_cfg['feature_reduction_method']\n",
    "\n",
    "X_reduced = X.copy()\n",
    "\n",
    "target_type = type_of_target(y)\n",
    "\n",
    "if method == 'No Reduction':\n",
    "    pass  \n",
    "\n",
    "elif method == 'Corr with Target':\n",
    "    corr = X.corrwith(y).abs()\n",
    "    top_features = corr.nlargest(int(feature_reduction_cfg['num_of_features_to_keep'])).index\n",
    "    X_reduced = X[top_features]\n",
    "\n",
    "elif method == 'Tree-based':\n",
    "    if target_type in ['binary', 'multiclass']:\n",
    "        model = RandomForestClassifier(n_estimators=int(feature_reduction_cfg['num_of_trees']),\n",
    "                                      max_depth=int(feature_reduction_cfg['depth_of_trees']),\n",
    "                                      random_state=42)\n",
    "    else:\n",
    "        model = RandomForestRegressor(n_estimators=int(feature_reduction_cfg['num_of_trees']),\n",
    "                                      max_depth=int(feature_reduction_cfg['depth_of_trees']),\n",
    "                                      random_state=42)\n",
    "\n",
    "    model.fit(X, y)\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    top_features = X.columns[np.argsort(importances)[::-1][:int(feature_reduction_cfg['num_of_features_to_keep'])]]\n",
    "    X_reduced = X[top_features]\n",
    "\n",
    "elif method == 'PCA':\n",
    "    pca = PCA(n_components=int(feature_reduction_cfg['num_of_features_to_keep']))\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_reduced = pd.DataFrame(X_pca, columns=[f'PCA_{i+1}' for i in range(X_pca.shape[1])])\n",
    "\n",
    "else:\n",
    "    warnings.warn(f\"Unknown reduction method: {method}\")\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat([X_reduced, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c7e3db-b899-432b-9395-ea2a7ca64fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_hashed_1</th>\n",
       "      <th>petal_width_div_species_sum</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_length_div_sepal_width</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000001</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.541666</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.100002</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.741935</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.600002</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.300001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.599999</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.000002</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.749999</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     species_hashed_1  petal_width_div_species_sum  petal_length  \\\n",
       "81                0.0                    -1.000001           3.7   \n",
       "139              -1.0                    -2.100002           5.4   \n",
       "129              -1.0                    -1.600002           5.8   \n",
       "89                0.0                    -1.300001           4.0   \n",
       "121              -1.0                    -2.000002           4.9   \n",
       "\n",
       "     petal_length_div_sepal_width  petal_width  \n",
       "81                       1.541666          1.0  \n",
       "139                      1.741935          2.1  \n",
       "129                      1.933333          1.6  \n",
       "89                       1.599999          1.3  \n",
       "121                      1.749999          2.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed55f585-4589-4c8b-94aa-00b69082161f",
   "metadata": {},
   "source": [
    "<font size='5'>**Train Test Split**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7c095c-a09d-4d9c-a4c1-6aab10ee2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323636a2-3194-46e1-ab4d-000ae2fb43ba",
   "metadata": {},
   "source": [
    "<font size='5'>**Probability Calibration**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5f657ab-3a3f-43ed-9996-3112f3b52df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_calibration = config['design_state_data'].get('probability_calibration', {})\n",
    "\n",
    "# Helper function to wrap classifier with CalibratedClassifierCV if needed\n",
    "def wrap_classifier_with_calibration(model, calibration_method):\n",
    "    if calibration_method == \"Sigmoid - Platt Scaling\":\n",
    "        return CalibratedClassifierCV(base_estimator=model, method='sigmoid')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b6685-22d6-4172-8801-0e6eb196b831",
   "metadata": {},
   "source": [
    "<font size='5'>**Model Selection**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c2777-8039-4d2d-b312-411bb054bfb5",
   "metadata": {},
   "source": [
    "1) Lists are created for regression and classification tasks based on prediction_type to reduce redundancy.\n",
    "2) A warning is generated if an unknown prediction_type is mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0bc8be-21ba-40b4-9fd1-89e1fbc7d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_type=config['design_state_data']['target']['prediction_type']\n",
    "if prediction_type=='Regression':\n",
    "    algorithms=['RandomForestRegressor','GBTRegressor','LinearRegression','RidgeRegression','LassoRegression','ElasticNetRegression','DecisionTreeRegressor','xg_boost','SVM','KNN','SGD','extra_random_trees','neural_network']\n",
    "    \n",
    "elif prediction_type=='Classification':\n",
    "    algorithms=['RandomForestClassifier','GBTClassifier','LogisticRegression','DecisionTreeClassifier','xg_boost','SVM','KNN','SGD','extra_random_trees','neural_network']\n",
    "\n",
    "else:\n",
    "    warnings.warn(f\"Unknown prediction_type: {prediction_type}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81706d75-ed5a-4e2f-9a3a-a9599158a9d9",
   "metadata": {},
   "source": [
    "1) It checks which model is selected for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa523728-bb53-4257-87a0-ec9a4429515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor\n"
     ]
    }
   ],
   "source": [
    "for model in algorithms:\n",
    "    if config['design_state_data']['algorithms'][model]['is_selected']==True:\n",
    "        model_selected=model\n",
    "        break\n",
    "print(model_selected)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df468216-25f6-4014-980d-a471c92ef426",
   "metadata": {},
   "source": [
    "<font size='5'>**Calibrated Models with JSON File**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993fdfa8-d82c-4121-8eea-84dfbee29112",
   "metadata": {},
   "source": [
    "1) Calibrating the original models using model parameters from the JSON file.\n",
    "2) Using parameters for hyperparameter tuning.\n",
    "3) Performing probability calibration as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1204ad3-a062-46e6-9b6d-8a17430c7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, RandomForestClassifier,\n",
    "    GradientBoostingRegressor, GradientBoostingClassifier,\n",
    "    ExtraTreesRegressor, ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, LogisticRegression,\n",
    "    Ridge, Lasso, ElasticNet,\n",
    "    SGDRegressor, SGDClassifier\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# model_cfg and model_selected should be defined externally\n",
    "model_cfg = config['design_state_data']['algorithms'][model_selected]\n",
    "\n",
    "\n",
    "# Helper function to adjust n_jobs\n",
    "def adjust_n_jobs(n_jobs):\n",
    "    return 1 if n_jobs == 0 else n_jobs\n",
    "\n",
    "model_mapping = {\n",
    "    'RandomForestRegressor': RandomForestRegressor,\n",
    "    'RandomForestClassifier': RandomForestClassifier,\n",
    "    'GBTRegressor': GradientBoostingRegressor,\n",
    "    'GBTClassifier': GradientBoostingClassifier,\n",
    "    'LinearRegression': LinearRegression,\n",
    "    'LogisticRegression': LogisticRegression,\n",
    "    'RidgeRegression': Ridge,\n",
    "    'LassoRegression': Lasso,\n",
    "    'ElasticNetRegression': ElasticNet,\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor,\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier\n",
    "}\n",
    "\n",
    "if model_selected in ['RandomForestRegressor', 'RandomForestClassifier']:\n",
    "    final_model = model_mapping[model_selected](\n",
    "        n_estimators=np.random.randint(model_cfg['min_trees'], model_cfg['max_trees']),\n",
    "        max_depth=np.random.randint(model_cfg['min_depth'], model_cfg['max_depth']),\n",
    "        min_samples_leaf=np.random.randint(model_cfg['min_samples_per_leaf_min_value'], model_cfg['min_samples_per_leaf_max_value']),\n",
    "        n_jobs=adjust_n_jobs(model_cfg['parallelism']),\n",
    "        random_state=42\n",
    "    )\n",
    "    if model_selected == 'RandomForestClassifier' and probability_calibration.get('probability_calibration_method'):\n",
    "        final_model = wrap_classifier_with_calibration(final_model, probability_calibration['probability_calibration_method'])\n",
    "    param_grid = {\n",
    "        'n_estimators': [model_cfg['min_trees'], model_cfg['max_trees']],\n",
    "        'max_depth': [model_cfg['min_depth'], model_cfg['max_depth']],\n",
    "        'min_samples_leaf': [model_cfg['min_samples_per_leaf_min_value'], model_cfg['min_samples_per_leaf_max_value']]\n",
    "    }    \n",
    "\n",
    "elif model_selected in ['GBTRegressor', 'GBTClassifier']:\n",
    "    final_model = model_mapping[model_selected](\n",
    "        n_estimators=np.random.randint(model_cfg['num_of_BoostingStages'][0], model_cfg['num_of_BoostingStages'][1]),\n",
    "        learning_rate=np.random.uniform(model_cfg['min_stepsize'], model_cfg['max_stepsize']),\n",
    "        subsample=np.random.uniform(model_cfg['min_subsample'], model_cfg['max_subsample']),\n",
    "        max_depth=np.random.randint(model_cfg['min_depth'], model_cfg['max_depth']),\n",
    "        random_state=42\n",
    "    )\n",
    "    if model_selected == 'GBTClassifier' and probability_calibration.get('probability_calibration_method'):\n",
    "        final_model = wrap_classifier_with_calibration(final_model, probability_calibration['probability_calibration_method'])\n",
    "    param_grid = {\n",
    "        'n_estimators': [model_cfg['num_of_BoostingStages'][0], model_cfg['num_of_BoostingStages'][1]],\n",
    "        'learning_rate': [model_cfg['min_stepsize'], model_cfg['max_stepsize']],\n",
    "        'subsample': [model_cfg['min_subsample'], model_cfg['max_subsample']],\n",
    "        'max_depth': [model_cfg['min_depth'], model_cfg['max_depth']]\n",
    "    }\n",
    "    \n",
    "elif model_selected in ['LinearRegression', 'LogisticRegression']:\n",
    "    final_model = model_mapping[model_selected](\n",
    "        alpha=np.random.uniform(model_cfg['min_regparam'], model_cfg['max_regparam']),\n",
    "        l1_ratio=np.random.uniform(model_cfg['min_elasticnet'], model_cfg['max_elasticnet']),\n",
    "        max_iter=np.random.randint(model_cfg['min_iter'], model_cfg['max_iter']),\n",
    "        n_jobs=adjust_n_jobs(model_cfg['parallelism']),\n",
    "        random_state=42\n",
    "    )\n",
    "    if model_selected == 'LogisticRegression' and probability_calibration.get('probability_calibration_method'):\n",
    "        final_model = wrap_classifier_with_calibration(final_model, probability_calibration['probability_calibration_method'])\n",
    "    param_grid = {\n",
    "        'alpha': [model_cfg['min_regparam'], model_cfg['max_regparam']],\n",
    "        'l1_ratio': [model_cfg['min_elasticnet'], model_cfg['max_elasticnet']],\n",
    "        'max_iter': [model_cfg['min_iter'], model_cfg['max_iter']]\n",
    "    }\n",
    "elif model_selected in ['RidgeRegression', 'LassoRegression']:\n",
    "    final_model = model_mapping[model_selected](\n",
    "        alpha=np.random.uniform(model_cfg['min_regparam'], model_cfg['max_regparam']),\n",
    "        max_iter=np.random.randint(model_cfg['min_iter'], model_cfg['max_iter']),\n",
    "        random_state=42\n",
    "    )\n",
    "    param_grid = {\n",
    "        'alpha': [model_cfg['min_regparam'], model_cfg['max_regparam']],\n",
    "        'max_iter': [model_cfg['min_iter'], model_cfg['max_iter']]\n",
    "    }\n",
    "\n",
    "elif model_selected == 'ElasticNetRegression':\n",
    "    final_model = model_mapping[model_selected](\n",
    "        alpha=np.random.uniform(model_cfg['min_regparam'], model_cfg['max_regparam']),\n",
    "        l1_ratio=np.random.uniform(model_cfg['min_elasticnet'], model_cfg['max_elasticnet']),\n",
    "        max_iter=np.random.randint(model_cfg['min_iter'], model_cfg['max_iter']),\n",
    "        random_state=42\n",
    "    )\n",
    "    param_grid = {\n",
    "        'alpha': [model_cfg['min_regparam'], model_cfg['max_regparam']],\n",
    "        'l1_ratio': [model_cfg['min_elasticnet'], model_cfg['max_elasticnet']],\n",
    "        'max_iter': [model_cfg['min_iter'], model_cfg['max_iter']]\n",
    "    }\n",
    "    \n",
    "elif model_selected in ['DecisionTreeRegressor', 'DecisionTreeClassifier']:\n",
    "    final_model = model_mapping[model_selected](\n",
    "        max_depth=np.random.randint(model_cfg['min_depth'], model_cfg['max_depth'] + 1),\n",
    "        min_samples_leaf=np.random.randint(model_cfg['min_samples_per_leaf'][0], model_cfg['min_samples_per_leaf'][1] + 1),\n",
    "        criterion='entropy' if model_cfg.get('use_entropy', False) else 'gini',\n",
    "        random_state=42\n",
    "    )\n",
    "    if model_selected == 'DecisionTreeClassifier' and probability_calibration.get('probability_calibration_method'):\n",
    "        final_model = wrap_classifier_with_calibration(final_model, probability_calibration['probability_calibration_method'])\n",
    "    param_grid = {\n",
    "        'max_depth': [model_cfg['min_depth'], model_cfg['max_depth']],\n",
    "        'min_samples_leaf': [model_cfg['min_samples_per_leaf'][0], model_cfg['min_samples_per_leaf'][1]],\n",
    "        'criterion': ['gini', 'entropy'] if model_cfg.get('use_entropy', False) else ['gini']\n",
    "    }\n",
    "    \n",
    "elif model_selected == 'xg_boost':\n",
    "    model_class = XGBRegressor if prediction_type == 'Regression' else XGBClassifier\n",
    "    final_model = model_class(\n",
    "        booster='dart',\n",
    "        n_jobs=adjust_n_jobs(model_cfg['parallelism']),\n",
    "        max_depth=np.random.randint(model_cfg['max_depth_of_tree'][0], model_cfg['max_depth_of_tree'][1]),\n",
    "        learning_rate=np.random.uniform(model_cfg['learningRate'][0], model_cfg['learningRate'][1]),\n",
    "        reg_alpha=model_cfg['l1_regularization'][0],\n",
    "        reg_lambda=model_cfg['l2_regularization'][0],\n",
    "        gamma=model_cfg['gamma'][0],\n",
    "        min_child_weight=model_cfg['min_child_weight'][0],\n",
    "        subsample=model_cfg['sub_sample'][0],\n",
    "        colsample_bytree=model_cfg['col_sample_by_tree'][0],\n",
    "        random_state=42\n",
    "    )\n",
    "    if prediction_type == 'Classification' and probability_calibration.get('probability_calibration_method'):\n",
    "        final_model = wrap_classifier_with_calibration(final_model, probability_calibration['probability_calibration_method'])\n",
    "    param_grid = {\n",
    "        'max_depth': [model_cfg['max_depth_of_tree'][0], model_cfg['max_depth_of_tree'][1]],\n",
    "        'learning_rate': [model_cfg['learningRate'][0], model_cfg['learningRate'][1]],\n",
    "        'reg_alpha': [model_cfg['l1_regularization'][0]],\n",
    "        'reg_lambda': [model_cfg['l2_regularization'][0]],\n",
    "        'gamma': [model_cfg['gamma'][0]],\n",
    "        'min_child_weight': [model_cfg['min_child_weight'][0]],\n",
    "        'subsample': [model_cfg['sub_sample'][0]],\n",
    "        'colsample_bytree': [model_cfg['col_sample_by_tree'][0]]\n",
    "    }\n",
    "    \n",
    "elif model_selected == 'SVM':\n",
    "    model_class = SVR if prediction_type == 'Regression' else SVC\n",
    "    final_model = model_class(\n",
    "        C=model_cfg['c_value'],\n",
    "        kernel='rbf',\n",
    "        tol=model_cfg['tolerance'],\n",
    "        max_iter=model_cfg['max_iter']\n",
    "    )\n",
    "    if prediction_type == 'Classification' and probability_calibration.get('probability_calibration_method'):\n",
    "        final_model = wrap_classifier_with_calibration(final_model, probability_calibration['probability_calibration_method'])\n",
    "    param_grid = {\n",
    "        'C': [model_cfg['c_value']],\n",
    "        'kernel': ['rbf'],\n",
    "        'tol': [model_cfg['tolerance']],\n",
    "        'max_iter': [model_cfg['max_iter']]\n",
    "    }\n",
    "    \n",
    "elif model_selected == 'SGD':\n",
    "    model_class = SGDRegressor if prediction_type == 'Regression' else SGDClassifier\n",
    "    final_model = model_class(\n",
    "        alpha=np.random.uniform(model_cfg['alpha_value'][0], model_cfg['alpha_value'][1]),\n",
    "        l1_ratio=0.15,\n",
    "        tol=model_cfg['tolerance'],\n",
    "        loss='log', \n",
    "        n_jobs=adjust_n_jobs(model_cfg['parallelism']),\n",
    "        random_state=42\n",
    "    )\n",
    "    if prediction_type == 'Classification' and probability_calibration.get('probability_calibration_method'):\n",
    "        final_model = wrap_classifier_with_calibration(final_model, probability_calibration['probability_calibration_method'])\n",
    "    param_grid = {\n",
    "        'alpha': [model_cfg['alpha_value'][0], model_cfg['alpha_value'][1]],\n",
    "        'l1_ratio': [0.15],\n",
    "        'tol': [model_cfg['tolerance']]\n",
    "    }\n",
    "\n",
    "\n",
    "elif model_selected == 'KNN':\n",
    "    model_class = KNeighborsRegressor if prediction_type == 'Regression' else KNeighborsClassifier\n",
    "    final_model = model_class(\n",
    "        n_neighbors=model_cfg['k_value'][0],\n",
    "        weights='distance',\n",
    "        algorithm='auto',\n",
    "        p=model_cfg['p_value']\n",
    "    )\n",
    "    if prediction_type == 'Classification' and probability_calibration.get('probability_calibration_method'):\n",
    "        final_model = wrap_classifier_with_calibration(final_model, probability_calibration['probability_calibration_method'])\n",
    "    param_grid = {\n",
    "        'n_neighbors': [model_cfg['k_value'][0]],\n",
    "        'weights': ['distance'],\n",
    "        'algorithm': ['auto'],\n",
    "        'p': [model_cfg['p_value']]\n",
    "    }\n",
    "    \n",
    "elif model_selected == 'extra_random_trees':\n",
    "    model_class = ExtraTreesRegressor if prediction_type == 'Regression' else ExtraTreesClassifier\n",
    "    final_model = model_class(\n",
    "        n_estimators=np.random.randint(model_cfg['num_of_trees'][0], model_cfg['num_of_trees'][1]),\n",
    "        max_depth=np.random.randint(model_cfg['max_depth'][0], model_cfg['max_depth'][1]),\n",
    "        min_samples_leaf=np.random.randint(model_cfg['min_samples_per_leaf'][0], model_cfg['min_samples_per_leaf'][1]),\n",
    "        max_features='sqrt', \n",
    "        n_jobs=adjust_n_jobs(model_cfg['parallelism']),\n",
    "        random_state=42\n",
    "    )\n",
    "    if model_selected == 'ExtraTreesClassifier' and probability_calibration.get('probability_calibration_method'):\n",
    "        final_model = wrap_classifier_with_calibration(final_model, probability_calibration['probability_calibration_method'])\n",
    "    param_grid = {\n",
    "        'n_estimators': [model_cfg['num_of_trees'][0], model_cfg['num_of_trees'][1]],\n",
    "        'max_depth': [model_cfg['max_depth'][0], model_cfg['max_depth'][1]],\n",
    "        'min_samples_leaf': [model_cfg['min_samples_per_leaf'][0], model_cfg['min_samples_per_leaf'][1]]\n",
    "    }\n",
    "    \n",
    "elif model_selected == 'neural_network':\n",
    "    model_class = MLPRegressor if prediction_type == 'Regression' else MLPClassifier\n",
    "    final_model = model_class(\n",
    "        hidden_layer_sizes=(np.random.randint(model_cfg['hidden_layer_size'][0], model_cfg['hidden_layer_size'][1]),),\n",
    "        alpha=np.random.uniform(model_cfg['min_alpha'], model_cfg['max_alpha']),\n",
    "        early_stopping=model_cfg['early_stopping'],\n",
    "        solver=model_cfg['solver'],\n",
    "        shuffle=model_cfg['shuffle_data'],\n",
    "        random_state=42\n",
    "    )\n",
    "    if prediction_type == 'Classification' and probability_calibration.get('probability_calibration_method'):\n",
    "        final_model = wrap_classifier_with_calibration(final_model, probability_calibration['probability_calibration_method'])\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(model_cfg['hidden_layer_size'][0],), (model_cfg['hidden_layer_size'][1],)],\n",
    "        'alpha': [model_cfg['min_alpha'], model_cfg['max_alpha']]\n",
    "    }    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3048812-1229-4a4c-adcc-144d3ba88204",
   "metadata": {},
   "source": [
    "<font size='5'>**Hyper-parameter Tuning**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f9dc330-5dfb-4196-9244-2d22a25a6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, TimeSeriesSplit\n",
    "hyperparameter_strategy = config['design_state_data'].get('hyperparameters', {})\n",
    "if hyperparameter_strategy.get('strategy') == \"Grid Search\":\n",
    "    cv = get_cv_strategy(\n",
    "        prediction_type=prediction_type,\n",
    "        cv_strategy=hyperparameter_strategy.get('cross_validation_strategy', ''),\n",
    "        num_folds=hyperparameter_strategy.get('num_of_folds', 5),\n",
    "        shuffle=hyperparameter_strategy.get('shuffle_grid', False),\n",
    "        random_state=hyperparameter_strategy.get('random_state', None),\n",
    "        stratified=hyperparameter_strategy.get('stratified', False)\n",
    "    )\n",
    "    final_model = GridSearchCV(\n",
    "        estimator=final_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        n_jobs=adjust_n_jobs(hyperparameter_strategy.get('parallelism', 1)),\n",
    "        scoring=None,  # Use default scoring for the model\n",
    "        random_state=hyperparameter_strategy.get('random_state', None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039649db-035d-497f-bc93-477c9af979c6",
   "metadata": {},
   "source": [
    "<font size='5'>**Weighting Strategy**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd5ed21-a041-4e80-b025-040fff48cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighting_strategy = config['design_state_data'].get('weighting_strategy', {})\n",
    "if prediction_type == 'Classification' and weighting_strategy.get('weighting_strategy_method') == 'Sample weights':\n",
    "    weight_variable = weighting_strategy.get('weighting_strategy_weight_variable')\n",
    "    if weight_variable in X_train.columns:\n",
    "        sample_weights = X_train[weight_variable].values\n",
    "        final_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "    else:\n",
    "        warnings.warn(f\"Weight variable '{weight_variable}' not found in dataset columns.\")\n",
    "else:\n",
    "    final_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ec240-27be-4634-917f-5065d526b14e",
   "metadata": {},
   "source": [
    "<font size='5'>**Model Prediction**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34d1b0e3-ebdd-4159-9bce-8ba24a4b05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e21d662-0e60-400c-abf5-67d49788b20f",
   "metadata": {},
   "source": [
    "<font size='5'>**Model Evaluation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e794f1b-409f-43af-88d7-925c257e884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.004562253018305402\n",
      "R2 Score: 0.99282275915245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, r2_score, recall_score, precision_score\n",
    "\n",
    "if prediction_type == 'Classification':\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "elif prediction_type == 'Regression':\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R2 Score: {r2}\")\n",
    "else:\n",
    "    print(\"Unknown prediction type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe782310-f23e-42d4-b271-121ef0212a45",
   "metadata": {},
   "source": [
    "<font size='5'>**Summary**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2826d-c0f7-4262-b709-2bcfe44ccc91",
   "metadata": {},
   "source": [
    "\r\n",
    "1) This code can be used for any machine learning problem, supporting both classification and regression tasks with a wide range of algorithms.\r\n",
    "2) It covers all important steps in the ML problem, including data loading, preprocessing with feature hashing and interaction generation, dimensionality reduction, model training with hyperparameter tuning, and evaluation using relevant metrics.\r\n",
    "3) However, the provided JSON file must follow the same format as given in \"algoparams_from_ui.json\" for the pipeline to function correctly.\r\n",
    "4) And file should be in **JSON Format** only not in **Rich Format**, if **Rich Format** then convert to **JSON**.\r\n",
    "\r\n",
    "Conclusion: This pipeline offers a flexible and comprehensive solution for any ML task, provided the configuration adheres to the specified JSON structure and is properly formatted, ensuring seamless execution and effective model performance.mance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d618de-13ec-4660-a13f-8ec560239f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79531947-cf27-44d2-b400-b9fb066a67e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
